---
title: "Deskriptive Analyse"
output: html_document
---

## Employee Churn
# Prediction Martin

```{r}
library(readxl)
library(ggplot2)
library(tidyr)
library(stringr)
library(lubridate)
library(mltools)
library(data.table)
library(mlbench)
library(tidyverse)
library(magrittr)

#tree
library(tree)
library(caret)
library(caretEnsemble)
library(rpart)
library(rpart.plot)
```


## Datenimport und -vorbereitung
```{r}
hot_df <- read_xlsx("20220110_dataPrepped_afterOneHot.xlsx")
hot_df <- subset(hot_df, 
                  select = -c(EmployeeChurned_1, `start_Cost center`))


colnames(hot_df)[colnames(hot_df) == "EmployeeChurned_0"] <- "EmployeeChurned"
colnames(hot_df)[colnames(hot_df) == "Temporary_0"] <- "Temporary"

hot_df$EmployeeChurned <- as.factor(hot_df$EmployeeChurned)
#hot_df$Gender <- as.factor(hot_df$Gender)

# Kategorische Variablen
factorCols <- c("Gender",
                "TemporaryPersonel",
                "Part Time Mark",
                "NonExempt",
                "start_NonExempt",
                "development to exempt"
                )

# Umwandlung in kategorische Variablen
hot_df %<>% mutate_at(factorCols, factor)

#Indexspalte
hot_df$index <- 1:nrow(hot_df)
str(hot_df)

```

## Train Test Split 
```{r}
#tree.hot_df=tree(EmployeeChurned_0)
#hot_df.seed()

hot_df$EmployeeChurned <- as.factor(hot_df$EmployeeChurned)
hot_df$Gender <- as.factor(hot_df$Gender)
hot_df$Gender <- as.factor(hot_df$Gender)
hot_df$decrease_Category_People <- as.factor(hot_df$decrease_Category_People)


head(hot_df)
inTrain <- createDataPartition(y=hot_df$EmployeeChurned, p = .75, list=FALSE)

training <- hot_df[ inTrain,]
testing  <- hot_df[-inTrain,]

str(testing)
```
#tree simple
```{r}
simpleTreeFit <- tree(EmployeeChurned ~ 
                        training$`Vertical_Horizontal_Developments_1-2` +
                        training$Vertical_Horizontal_Developments_0 +
                        training$Gender +
                        training$`Months Since Last Development` +
                        training$`Part Time Mark` +
                        training$`Month Of Service`, data = training)
plot(simpleTreeFit)
text(simpleTreeFit, pretty = 0)

#nur metrische Werte
```


#rpart initial
```{r}
rpartInitial <- rpart(EmployeeChurned ~ Gender + 
                        `Month Of Service` +
                        `Months Since Last Development`,
                      data=training,
                      control= rpart.control(cp=0.01))

printcp(rpartInitial)
prp(rpartInitial)
```


#rpart specifications
```{r}
rpartFit <- rpart(EmployeeChurned ~ . -index, data = training, method = "class",control = rpart.control(maxdepth = 5, minsplit = 5))
rpart.plot(rpartFit)
#
```


#h2o
```{r}
library(h2o)
h2o.init()

#import as h2o dataframe
#20220110_dataPrepped_afterOneHot.xlsx
#iris_path <- "../smalldata/iris/iris_wheader.csv"
#iris_path <- "20220110_dataPrepped_afterOneHot.xlsx"
#iris <- h2o.uploadFile(path = iris_path)
trainingH2O <- as.h2o(training)
testingH2O <- as.h2o(testing)

predictors <- c("Gender", "Month Of Service" ,
                "Months Since Last Development",
                "Part Time Mark",
                "Paybands_A", "Paybands_B", "Paybands_C", "Paybands_D")
response <- "EmployeeChurned"



h2oFit <- h2o.randomForest(x = predictors,
                             y = response,
                             ntrees = 10,
                             max_depth = 5,
                             min_rows = 10,
                             min_split_improvement = 0.0001,
                             calibrate_model = FALSE,
                             binomial_double_trees = TRUE,
                             training_frame = trainingH2O,
                             nfolds = 5)

#validation_frame = testingH2O,
#calibration_frame = testingH2O,


perf <- h2o.performance(h2oFit)
perf
h2o.confusionMatrix(h2oFit) #or perf

perf <- h2o.performance(h2oFit, testingH2O)
h2o.confusionMatrix(perf)


predict <- h2o.predict(h2oFit, newdata = testingH2O)
head(predict, 100)
perfPredict <- h2o.performance(predict)

curve_data <- data.frame(perf@metrics$thresholds_and_metric_scores) %>% select(c(tpr,fpr))

ggplot(curve_data, aes(x = fpr, y = tpr)) +
    geom_point() +
    geom_line() +
    geom_segment(
        aes(x = 0, y = 0, xend = 1, yend = 1),
        linetype = "dotted",
        color = "grey50"
        ) +
    xlab("False Positive Rate") +
    ylab("True Positive Rate") +
    ggtitle("ROC Curve") +
    theme_bw()


#h2o.confusionMatrix(perf)  -> for predict

#h2o_drl_auc <- h2oFit.multinomial_auc_table(trainingH2O)
library(pROC)
auc(testingH2O)


#https://docs.h2o.ai/h2o/latest-stable/h2o-docs/performance-and-prediction.html?highlight=confusion%20matrix
```


#caret train
```{r}
#test 
#hot_df$`Months Since Last Development`
treeFit <- train(EmployeeChurned ~ `Month Of Service`,
                     data = training,
                     method = "bstTree")
plot(treeFit)
text(treeFit, pretty =0)

#keine metrischen Werte
```
#caret predict
```{r}
treePredict <- predict(treeFit, newdata = testing)
#head(treePredict)
confusionMatrix(data = treePredict, testing$EmployeeChurned)
```


