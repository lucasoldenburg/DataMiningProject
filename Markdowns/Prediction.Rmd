---
title: "Deskriptive Analyse"
output: html_document
---

## Employee Churn
# Prediction Martin

```{r}
library(readxl)
library(ggplot2)
library(tidyr)
library(stringr)
library(lubridate)
library(mltools)
library(data.table)
library(mlbench)
library(tidyverse)
library(magrittr)
library(caret)

#tree
library(rpart)
library(rpart.plot)
library(ROCR)
library(h2o)
h2o.init()

```


## Datenimport und -vorbereitung 
```{r}
# Datenset nach One-Hot-Encoding
hot_df <- read_xlsx("20220110_dataPrepped_afterOneHot.xlsx")
hot_df <- subset(hot_df, 
                  select = -c(EmployeeChurned_0, `start_Cost center`,
                              `start_Calendar Year/Month`,
                              `LastActive_Calendar Year/Month`))

colnames(hot_df)[colnames(hot_df) == "EmployeeChurned_1"] <- "EmployeeChurned"

# Kategorische Variablen
factorColsOneHot <- c("Gender",
                "TemporaryPersonel",
                "Part Time Mark",
                "NonExempt",
                "start_NonExempt",
                "development to exempt",
                "Vertical_Horizontal_Developments_>= 3",
                "Vertical_Horizontal_Developments_0",
                "Vertical_Horizontal_Developments_1-2",
                "start_contract type_apprentice",
                "start_contract type_permanent staff",
                "start_contract type_temporary personnel",
                "start_Part time mark",
                "EmployeeChurned",
                "decrease_Category_Customer",
                "decrease_Category_GB Management",
                "decrease_Category_GBR/N",
                "decrease_Category_GTU GD",
                "decrease_Category_Human Resources GBS",
                "decrease_Category_Intellectual Property",
                "decrease_Category_IT Service CC",
                "decrease_Category_People",
                "decrease_Category_Planning & Development",
                "decrease_Category_Procurement Services - GP",
                "decrease_Category_RAA/A Competence",
                "decrease_Category_Safety",
                "decrease_Category_Supplier & Reporting",
                "Nationality_Classification_EU",
                "Nationality_Classification_German",
                "Nationality_Classification_Other",
                "Paybands_A",
                "Paybands_B",
                "Paybands_C",
                "Paybands_D",
                "Paybands_E",
                "Paybands_F",
                "Paybands_G",
                "Paybands_H")

# Umwandlung in kategorische Variablen
hot_df %<>% mutate_at(factorColsOneHot, factor)

#Indexspalte
#hot_df$index <- 1:nrow(hot_df)



# Rohdatenset ohne One-Hot-Encoding
raw_df <- read_xlsx("20220110_dataPrepped_beforeOneHot.xlsx")

raw_df <- subset(raw_df, 
                  select = -c(`start_Cost center`,
                              `start_Calendar Year/Month`,
                              `LastActive_Calendar Year/Month`))

# Kategorische Variablen
factorCols <- c("Gender",
                "TemporaryPersonel",
                "Part Time Mark",
                "NonExempt",
                "start_NonExempt",
                "development to exempt",
                "Vertical_Horizontal_Developments",
                "start_contract type",
                "start_Part time mark",
                "EmployeeChurned",
                "decrease_Category",
                "Nationality_Classification",
                "Paybands")

raw_df %<>% mutate_at(factorCols, factor)
```

## Train Test Split (sample)
```{r}
hot_df_asDataframe <- data.frame(hot_df)
sortedDF <- sort(sample(nrow(hot_df_asDataframe), nrow(hot_df_asDataframe)*.75))
train<-hot_df_asDataframe[sortedDF,]
test<-hot_df_asDataframe[-sortedDF,]


raw_df_asDataframe <- data.frame(raw_df)
raw_sortedDF <- sort(sample(nrow(raw_df_asDataframe), nrow(raw_df_asDataframe)*.75))
raw_train<-raw_df_asDataframe[raw_sortedDF,]
raw_test<-raw_df_asDataframe[-raw_sortedDF,]
```

## Train Test Split (h2o)
```{r}
hot_dfH2O <- as.h2o(hot_df)
splits <- h2o.splitFrame(data =  hot_dfH2O, ratios = 0.75, seed = 1234)
trainH2O <- splits[[1]]
testH2O <- splits[[2]]

raw_dfH2O <- as.h2o(raw_df)
splits <- h2o.splitFrame(data =  raw_dfH2O, ratios = 0.75, seed = 1234)
raw_trainH2O <- splits[[1]]
raw_testH2O <- splits[[2]]
```

# Find Features
```{r}
#Grid Search
#Hyperparameter

#feature importance
#one hot or not?
```



# Einfacher Entscheidungsbaum mit rpart-Bibliothek
```{r}
raw_rpart_control <- trainControl(
    method = "repeatedcv",
    number = 5,
    repeats = 10
)

rpart_grid <- expand.grid(cp = c(0.015, 0.01, 0.005, 0.001, 
                                 0.0005, 0.0001, 0.00001))

raw_rpart_fit <- train(EmployeeChurned ~ ., 
                       method = "rpart",
                       na.action = na.omit,
                       trControl = raw_rpart_control,
                       tuneGrid = rpart_grid,
                       data = raw_train)

best_cp <- raw_rpart_fit$bestTune[1,1]
best_cp 
```
# Modell mit optimalen Parametern trainieren
```{r}
raw_rpart <- rpart(EmployeeChurned ~., y = TRUE, x = TRUE,
                  data=raw_train,
                      control= rpart.control(cp=best_cp))

raw_rpart_prediction <- rpart.predict(raw_rpart, raw_test)
raw_rpart_prediction <- data.frame(raw_rpart_prediction)
raw_test$prob <- raw_rpart_prediction$`X1`
raw_test$EmployeeChurned <- as.numeric(as.character(raw_test$EmployeeChurned))
raw_test
```


# Allgemeine Modellgüte anhand der ROC-Kurve bestimmen
```{r}
<<<<<<< HEAD
# fpr_rocr <- perf_rocr@x.values[[1]]
=======
pred_rocr <- prediction(raw_test$prob, raw_test$EmployeeChurned)
perf_rocr <- performance(pred_rocr, "tpr", "fpr" )

fpr_rocr <- perf_rocr@x.values[[1]]
>>>>>>> e1f6da4c58f4f2ab0af69fc42247fdde4e0889fd
tpr_rocr <- perf_rocr@y.values[[1]]
threshold_rocr <- perf_rocr@alpha.values[[1]] 

#AUC - Fläche unter der ROC-Kurve als Gütemerkmal
performance(pred_rocr, "auc")@y.values

# Darstellung der ROC-Kurve
plot(perf_rocr, col="blue")
abline(0,1)
```
Die Fläche unterhalb der ROC-Kurve ist mit 0,71 größer als 0,5 und damit liefert 
das erstellte Modell eine genauere Vorhersage als bloßes Raten.

# Auswahl Threshold
```{r}
#Funktion zur Klassifizierung der Vorhersage
classify <- function(x, threshold){
  ifelse(x < threshold,0,1)
}

#Auswahl Threshold aus ROC-Kurve ("Ellenbogenpunkt")
threshold_predict <- 0.25

#Anwendung auf Testdatensatz
raw_test$predict <-classify(raw_test$prob, threshold_predict)
head(raw_test_showPredict <- subset(raw_test, select = c(prob,predict)),10)
```

# Modellgüte anhand der Konfusionsmatrix bestimmen
```{r}
confusionMatrix(factor(raw_test$predict), raw_test$EmployeeChurned,
                positive = "1")
```
Aufgrund des niedrigen Schwellenwertes, ist die Genauigkeit (Accuracy) gering. 
Dafür weißt die balanzierte Genauigkeit (Balanced Accuracy) einen höheren Wert
als die klassische Genauigkeit auf. 
Es wird tendenziell erhöht auf eine Abwanderung der Mitarbeiter:innen klassifiziert.
Dabei ist die geringe Spezifizität ist auf die hohe Zahl an FN-klassifizierten Werten 
zurückzuführen. 
Im Anwendungsfall ist dies nicht von Nachteil, da besonders FP-Klassifikationen
vermieden werden sollten. Um dies aktiv in die Modellierung zu integrieren 
sollen die mit den Fehlklassifikationen verbundenen Kosten in die Betrachtung
mit einbezogen werden.

# Kosten für Fehlklassifikationen
```{r}
#Kosten für neues Recruiting (Suchauftrag, Recruitingaufwand wie Planung, Gespräche, Onboarding)
cost_FP <- 3000  
#Kosten aufgrund von Zeit für Manager:in und Mitarbeiter:in sowie zusätzliche Trainings- oder Gehaltskosten
cost_FN <- 500 

matrix_overview_cost <- matrix(c(0,3000,500,0), nrow=2)
colnames(matrix_overview_cost) <- c("Mitarbeiter:in geht", "Mitarbeiter:in bleibt")
rownames(matrix_overview_cost) <- c("Vorhersage Mitarbeiter:in geht", "Vorhersage Mitarbeiter:in bleibt")
matrix_overview_cost
```

# Optimierung mit Kostenfunktion
```{r}
pred_class <- function(x, threshold){
  ifelse(x < threshold,0,1)
}

cost <- function(prob, actual,threshold2, cost_FN_func, cost_FP_func){
    predicted_automate2 <- pred_class(prob,threshold2)
    count_FN <- sum(predicted_automate2 == 1 & actual == "0")
    count_FP <- sum(predicted_automate2 == 0 & actual == "1")
    cost <- count_FN * cost_FN_func + count_FP * cost_FP_func
    return (cost)
}

threshold_input <- c(0.05, 0.1, 0.15, 0.16, 0.17, 0.2, 0.23, 0.24, 0.25,
                     0.3, 0.35, 0.45, 0.7) 

i <- 1
costs <- c()

while (i < length(threshold_input)+1) {
    costs[[(length(costs) +1)]] <- cost(raw_test$prob, raw_test$EmployeeChurned, 
                                         threshold_input[i], cost_FN, cost_FP)
    i <- i+1
}

cost_matrix <- matrix(c(threshold_input,costs),nrow=length(threshold_input))
colnames(cost_matrix) <- c("Threshold", "Kosten in Euro")
cost_matrix
```
Mit Betrachtung der Kosten liegt der optimale Threshold für das Model bei 0,16
und sollte für Vorhersagen eingesetzt werden.

# Auswahl Threshold aus ROC-Kurve ("Ellenbogenpunkt")
```{r}
threshold_optimum <- 0.16

raw_test$predict_optimum <-classify(raw_test$prob, threshold_optimum)

confusionMatrix(factor(raw_test$predict_optimum), raw_test$EmployeeChurned,
                positive = "1")
```
Es werden fast alle Mitarbeiter:innen erkannt, die das Unternehmen verlassen.
Allerdings ist die FN-Klassifikation sehr hoch. Eine Spezifizität von circa
1/3 würde für einen hohen Aufwand bei Managern führen und nicht unbedingt für
deren Zuspruch sorgen.
Doch aufgrund der hohen Sensitivität kann eine noch gute balanzierte Genauigkeit
von dem Modell bei Anwendung auf die Testdaten erreicht werden.

# Visualisierung des Entscheidungsbaumes
```{r}
printcp(raw_rpart)
prp(raw_rpart)
```
Den stärksten Einflussfaktor bildet der Funktionsbereich in dem die Mitarbeiter:in
zum letzten aktiven Zeitpunkt tätig war. GB Management, Human Resources GBS und
Safety sind dabei die genannten Faktoren. Dabei handelt es sich um erst kürzlich
aufgebaute Einheiten, was die kurze Zugehörigkeit der Mitarbeiter:innen und
geringe Abwanderung beschreibt. In zukünftigen Anpassungen des Modells auf neue
Daten sollte dies schrittweise an die übrigen Funktionsbereiche angeglichen
werden.
Die nächste Spaltung erfolgt durch das Merkmal Befristung. 
Auch die Dauer der Unternehmenszugehörigkeit sowie der Zeitpunkt seit der
letzten Entwicklung kommen zum Einsatz, während das Alter und die Gehaltsstufe
in den darauffolgenden Splits relevant werden.

Nicht zum Einsatz kommen: "Part Time Mark", "NonExempt", "start_NonExempt",
                "development to exempt", "decrease_Category",
                "Nationality_Classification", "Paybands"


# h2o Distributed Random Forest (DRF)
Im DRF werden eine Reihe an Bäumen erzeugt. Jeder dieser lernt basierend auf einen Teil
des Datensets (Spalten und Reihen). Für die finale Vorhersage wird dann der Durchschnitt 
aus den Vorhersagen der einzelnen Bäume berechnet. Das verringert die Varianz.
Um robuste Bäume zu erhalten werden darüber hinaus auf jedem Level je Baum 
zufällig die betrachteten Spalten (Features) gewählt. Die Anzahl der verwendeten
Spalten wird dabei durch die Wurzel aus der Gesamtanzahl der Spalten definiert.

##H2O Distributed Random Forest und Grid-Search (Tuning Hyperparameter)
```{r}
predictors <- c(factorCols, "Month Of Service", "Age", "Months Since Last Development")
target <- "EmployeeChurned"

#Hyperparameter
drf_params <- list( balance_classes = c(TRUE, FALSE),
                    ntrees = c(30, 50, 70),
                    max_depth = c(10, 15, 20, 25),
                    min_split_improvement = c(0.001, 0.0001, 0.00001, 0.000001))
#0.0000001
```
##Hyperparameter
balance classes - default False
ntrees - default 50
max_depth - default 20
Min_split_improvement - default 0,00001

##Hyperparameterwahl
```{r}
#search_criteria strategy “Cartesian”
h2oGrid <- h2o.grid("drf", x = predictors, y = target,
            grid_id = "h2oGrid",
            training_frame = raw_trainH2O,
            hyper_params = drf_params)

#Auswahl der optimalen Parameter anhand der AUC der einzelnen Modelle
h2oGridPerf <- h2o.getGrid(grid_id = "h2oGrid",
                           sort_by = "auc",
                           decreasing = TRUE)

# Güte im Trainingsset
summary(h2oGridPerf)
best_drf <- h2o.getModel(h2oGridPerf@model_ids[[1]])
h2o.performance(best_drf, raw_testH2O)
```
## Auswahl Threshold
```{r}
best_drf
```
Der Threshold wird automatisch auf die Metrik F1 optimiert.
Empfohlener Threshold bei Maximierung von F1 bei 0,39.

## Auswahl Threshold
```{r}
# Anwendung auf Testset
predictBestGrid <- h2o.predict(best_drf, newdata = raw_testH2O)
#head(predictBestGrid, 20)

raw_drfPrediciton_df <- as.data.frame(predictBestGrid)
raw_testH2O_asdf <- as.data.frame(raw_testH2O)
raw_testH2O_asdf$prob <- raw_drfPrediciton_df$p1
raw_testH2O_asdf

raw_testH2O_asdf$EmployeeChurned <- as.numeric(as.character(raw_testH2O_asdf$EmployeeChurned))
raw_test

pred_rocr_drf <- prediction(raw_testH2O_asdf$prob, raw_testH2O_asdf$EmployeeChurned)
perf_rocr_drf <- performance(pred_rocr_drf, "tpr", "fpr" )

fpr_rocr <- perf_rocr_drf@x.values[[1]]
tpr_rocr <- perf_rocr_drf@y.values[[1]]
threshold_rocr_drf <- perf_rocr_drf@alpha.values[[1]] 

performance(pred_rocr, "auc")@y.values
# Darstellung der ROC-Kurve
plot(perf_rocr_drf, col="blue")
abline(0,1)
```
Beschreibung

## Auswahl Threshold aus ROC-Kurve ("Ellenbogenpunkt")
```{r}
threshold_drf <- 0.25

```

## Modellgüte anhand der Konfusionsmatrix bestimmen
```{r}
raw_testH2O_asdf$predict <-classify(raw_testH2O_asdf$prob, threshold_drf)

# Güte anhand Testset
best_drf_perf <- h2o.performance(model = best_drf,
                                  newdata = raw_testH2O)

best_drf_perf

curve_dataGrid <- data.frame(best_drf_perf@metrics$thresholds_and_metric_scores) %>% select(c(tpr,fpr))

best_drf_perf@metrics

ggplot(curve_dataGrid, aes(x = fpr, y = tpr)) +
    geom_point() +
    geom_line() +
    geom_segment(
        aes(x = 0, y = 0, xend = 1, yend = 1),
        linetype = "dotted",
        color = "grey50"
        ) +
    xlab("False Positive Rate") +
    ylab("True Positive Rate") +
    ggtitle("ROC Curve") +
    theme_bw()

```


##Güte
Ziel unten links klein (false positve)
h2o.varimp_plot(pros_gbm)



# drf first try without hyper
```{r}
predictors <- c(factorCols, "Month Of Service", "Age", "Months Since Last Development")
target <- "EmployeeChurned"

h2oFit <- h2o.randomForest(x = predictors,
                             y = target,
                             ntrees = 10,
                             max_depth = 5,
                             min_rows = 10,
                             min_split_improvement = 0.0001,
                             calibrate_model = FALSE,
                             binomial_double_trees = TRUE,
                             training_frame = trainH2O,
                             nfolds = 6)
#Check: verbose: Print scoring history to the console. For DRF, metrics are per tree. 
#This option is defaults to false (not enabled).

# Güte im Trainingsset
perfH2O <- h2o.performance(h2oFit)
perfH2O
h2o.confusionMatrix(h2oFit)

# Anwendung auf Testset
predict <- h2o.predict(h2oFit, newdata = raw_testH2O)
head(predict, 100)

# Güte anhand Testset
perfTestH2O <- h2o.performance(h2oFit, raw_testH2O)
h2o.confusionMatrix(perfTestH2O)

curve_data <- data.frame(perfTestH2O@metrics$thresholds_and_metric_scores) %>% select(c(tpr,fpr))

ggplot(curve_data, aes(x = fpr, y = tpr)) +
    geom_point() +
    geom_line() +
    geom_segment(
        aes(x = 0, y = 0, xend = 1, yend = 1),
        linetype = "dotted",
        color = "grey40"
        ) +
    xlab("False Positive Rate") +
    ylab("True Positive Rate") +
    ggtitle("ROC Curve") +
    theme_bw()

h2o.gainsLift(h2oFit, testH2O)
h2o.auc(perfH2O)
h2o.aucpr(perfH2O)
h2o.accuracy(perfH2O)

#https://docs.h2o.ai/h2o/latest-stable/h2o-docs/performance-and-prediction.html?highlight=confusion%20matrix
```

##h2o Random Forest (Teilset)
```{r}

predictorsSmall <- c("Gender", "Month Of Service" ,
                "Months Since Last Development",
                "Part Time Mark", "Age",
                "Paybands_A", "Paybands_B", "Paybands_C", "Paybands_D", "Paybands_E")

targetSmall <- "EmployeeChurned"

h2oFitS <- h2o.randomForest(x = predictorsSmall,
                             y = targetSmall,
                             ntrees = 10,
                             max_depth = 5,
                             min_rows = 10,
                             min_split_improvement = 0.0001,
                             calibrate_model = FALSE,
                             binomial_double_trees = TRUE,
                             training_frame = trainingH2O,
                             nfolds = 6)


# Güte im Trainingsset
perfS <- h2o.performance(h2oFitS)
perfS
h2o.confusionMatrix(h2oFitS)

# Anwendung auf Testset
predictS <- h2o.predict(h2oFitS, newdata = testingH2O)
head(predictS, 100)

# Güte anhand Testset
perfTestS <- h2o.performance(h2oFitS, raw_testH2O)
h2o.confusionMatrix(perfTestS)

curve_dataS <- data.frame(perfTestS@metrics$thresholds_and_metric_scores) %>% select(c(tpr,fpr))

ggplot(curve_dataS, aes(x = fpr, y = tpr)) +
    geom_point() +
    geom_line() +
    geom_segment(
        aes(x = 0, y = 0, xend = 1, yend = 1),
        linetype = "dotted",
        color = "grey50"
        ) +
    xlab("False Positive Rate") +
    ylab("True Positive Rate") +
    ggtitle("ROC Curve") +
    theme_bw()
```

#caret train
```{r}
#test 
#hot_df$`Months Since Last Development`
treeFit <- train(EmployeeChurned ~ `Month Of Service`,
                     data = training,
                     method = "bstTree")
plot(treeFit)
text(treeFit, pretty =0)

#keine metrischen Werte
```
#caret predict
```{r}
treePredict <- predict(treeFit, newdata = testing)
#head(treePredict)
confusionMatrix(data = treePredict, testing$EmployeeChurned)
```


